{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0a83e396",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import argparse\n",
    "import time \n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch.utils.data import Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "47e95859",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalize:\n",
    "    def __call__(self, img):\n",
    "        img = img.astype(np.float32) / 255\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "ea8132d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PIL2numpy:\n",
    "    def __call__(self, img):\n",
    "        return np.array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "dc60f607",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor:\n",
    "    def __call__(self, arr):\n",
    "        arr = torch.from_numpy(arr)\n",
    "        return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "72051bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneHot:\n",
    "    def __init__(self, num_classes=10):\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def __call__(self, target):\n",
    "        one_hot_target = np.zeros(self.num_classes, dtype=np.float32)\n",
    "        one_hot_target[target] = 1\n",
    "        return one_hot_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1b11d8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_axis_indexes(kernel_axis_length, center_index):\n",
    "    axis_indexes = []\n",
    "    for i in range(-center_index, kernel_axis_length - center_index):\n",
    "        axis_indexes.append(i)\n",
    "    return axis_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8f0c1116",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_axes_indexes(kernel_size, kernel_center):\n",
    "    indexes_a = get_axis_indexes(\n",
    "        kernel_axis_length=kernel_size[0],\n",
    "        center_index=kernel_center[0]\n",
    "    )\n",
    "    indexes_b = get_axis_indexes(\n",
    "        kernel_axis_length=kernel_size[1],\n",
    "        center_index=kernel_center[1]\n",
    "    )\n",
    "    return indexes_a, indexes_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "28104bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_weight_from_npy(weight_name, load_path):\n",
    "    weight = np.load(load_path, allow_pickle=True).item().get(weight_name)\n",
    "    return weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8487c730",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2d:\n",
    "    def __init__(\n",
    "        self, in_channels, out_channels, kernel_size, stride=1,\n",
    "        kernel_center=(0, 0), padding=0, convolution=False\n",
    "    ):\n",
    "        self.stride = stride\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        if isinstance(kernel_size, tuple):\n",
    "            self.kernel_size = kernel_size\n",
    "        else:\n",
    "            self.kernel_size = (kernel_size, kernel_size)\n",
    "        self.kernel_center = kernel_center\n",
    "        self.convolution = convolution\n",
    "        self.padding = padding\n",
    "\n",
    "        self.init_weights()\n",
    "\n",
    "    def load_weights(self, weight_name, bias_name, load_path):\n",
    "        self.conv_w = load_weight_from_npy(weight_name, load_path)\n",
    "        self.conv_b = load_weight_from_npy(bias_name, load_path)\n",
    "\n",
    "    def init_weights(self):\n",
    "        self.conv_w = self.init_weight(self.kernel_size, self.in_channels*self.out_channels)\n",
    "        self.conv_b = self.init_weight((1, 1), self.out_channels)\n",
    "\n",
    "    def init_weight(self, weight_shape, weight_count):\n",
    "        weight = []\n",
    "        for i in range(weight_count):\n",
    "            weight.append(2*np.random.random(weight_shape)-1)\n",
    "        return weight\n",
    "\n",
    "    def convolution_feed_x_l(self, y_l_minus_1, w_l, print_demo=False):\n",
    "        stride = self.stride\n",
    "        indexes_a, indexes_b = get_axes_indexes(w_l.shape, self.kernel_center)\n",
    "        y_l_minus_1 = np.pad(y_l_minus_1, self.padding)\n",
    "        h_out = int((y_l_minus_1.shape[0] - (self.kernel_size[0]-1) - 1) / stride + 1)\n",
    "        w_out = int((y_l_minus_1.shape[1] - (self.kernel_size[1]-1) - 1) / stride + 1)\n",
    "        x_l = np.zeros((h_out, w_out), dtype=np.float32)\n",
    "        if self.convolution:\n",
    "            g = 1  \n",
    "        else:\n",
    "            g = -1  \n",
    "        for i in range(h_out):\n",
    "            for j in range(w_out):\n",
    "                demo = np.zeros([y_l_minus_1.shape[0], y_l_minus_1.shape[1]], dtype=np.float32)\n",
    "                result = 0\n",
    "                element_exists = False\n",
    "                for a in indexes_a:\n",
    "                    for b in indexes_b:\n",
    "                        if (\n",
    "                            i*stride - g*a >= 0\n",
    "                            and j*stride - g*b >= 0\n",
    "                            and i*stride - g*a < y_l_minus_1.shape[0]\n",
    "                            and j*stride - g*b < y_l_minus_1.shape[1]\n",
    "                        ):\n",
    "                            result += \\\n",
    "                                y_l_minus_1[i*stride - g*a][j*stride - g*b] * \\\n",
    "                                w_l[indexes_a.index(a)][indexes_b.index(b)]\n",
    "                            demo[i*stride - g*a][j*stride - g*b] = \\\n",
    "                                w_l[indexes_a.index(a)][indexes_b.index(b)]\n",
    "                            element_exists = True\n",
    "                if element_exists:\n",
    "                    x_l[i][j] = result\n",
    "                    if print_demo:\n",
    "                        print('i=' + str(i) + '; j=' + str(j) + '\\n', demo)\n",
    "        return x_l\n",
    "\n",
    "    def convolution_back_dEdw_l(self, y_l_minus_1, dEdx_l, print_demo=False):\n",
    "        stride = self.stride\n",
    "        y_l_minus_1 = np.pad(y_l_minus_1, self.padding)\n",
    "        w_l_shape = self.conv_w[0].shape\n",
    "        indexes_a, indexes_b = get_axes_indexes(w_l_shape, self.kernel_center)\n",
    "        dEdw_l = np.zeros((w_l_shape[0], w_l_shape[1]), dtype=np.float32)\n",
    "        if self.convolution:\n",
    "            g = 1  \n",
    "        else:\n",
    "            g = -1 \n",
    "        for a in indexes_a:\n",
    "            for b in indexes_b:\n",
    "                demo = np.zeros([y_l_minus_1.shape[0], y_l_minus_1.shape[1]], dtype=np.float32)\n",
    "                result = 0\n",
    "                for i in range(dEdx_l.shape[0]):\n",
    "                    for j in range(dEdx_l.shape[1]):\n",
    "                        if (\n",
    "                            i*stride - g*a >= 0\n",
    "                            and j*stride - g*b >= 0\n",
    "                            and i*stride - g*a < y_l_minus_1.shape[0]\n",
    "                            and j*stride - g*b < y_l_minus_1.shape[1]\n",
    "                        ):\n",
    "                            result += \\\n",
    "                                y_l_minus_1[i*stride - g*a][j*stride - g*b] * \\\n",
    "                                dEdx_l[i][j]\n",
    "                            demo[i*stride - g*a][j*stride - g*b] = \\\n",
    "                                dEdx_l[i][j]\n",
    "                dEdw_l[indexes_a.index(a)][indexes_b.index(b)] = result\n",
    "                if print_demo:\n",
    "                    print('a=' + str(a) + '; b=' + str(b) + '\\n', demo)\n",
    "        return dEdw_l\n",
    "\n",
    "    def convolution_back_dEdy_l_minus_1(\n",
    "        self, dEdx_l, w_l, y_l_minus_1_shape, print_demo=False\n",
    "    ):\n",
    "        indexes_a, indexes_b = get_axes_indexes(w_l.shape, self.kernel_center)\n",
    "        dEdy_l_minus_1 = np.zeros((y_l_minus_1_shape[0] + 2*self.padding,\n",
    "                                   y_l_minus_1_shape[1] + 2*self.padding), dtype=np.float32)\n",
    "        if self.convolution:\n",
    "            g = 1 \n",
    "        else:\n",
    "            g = -1  \n",
    "        for i in range(dEdy_l_minus_1.shape[0]):\n",
    "            for j in range(dEdy_l_minus_1.shape[1]):\n",
    "                result = 0\n",
    "                demo = np.zeros([dEdx_l.shape[0], dEdx_l.shape[1]], dtype=np.float32)\n",
    "                for i_x_l in range(dEdx_l.shape[0]):\n",
    "                    for j_x_l in range(dEdx_l.shape[1]):\n",
    "                        a = g*i_x_l*self.stride - g*i\n",
    "                        b = g*j_x_l*self.stride - g*j\n",
    "                        if (\n",
    "                            a in indexes_a\n",
    "                            and b in indexes_b\n",
    "                        ):\n",
    "                            a = indexes_a.index(a)\n",
    "                            b = indexes_b.index(b)\n",
    "                            result += dEdx_l[i_x_l][j_x_l] * w_l[a][b]\n",
    "                            demo[i_x_l][j_x_l] = w_l[a][b]\n",
    "                dEdy_l_minus_1[i][j] = result\n",
    "                if print_demo:\n",
    "                    print('i=' + str(i) + '; j=' + str(j) + '\\n', demo)\n",
    "        dEdy_l_minus_1 = \\\n",
    "            dEdy_l_minus_1[self.padding:(y_l_minus_1_shape[0]+self.padding),\n",
    "                           self.padding:(y_l_minus_1_shape[1]+self.padding)]\n",
    "        return dEdy_l_minus_1\n",
    "\n",
    "    def __call__(self, y_l_minus_1):\n",
    "        x_l = []\n",
    "        for i in range(self.in_channels):\n",
    "            for j in range(i*self.out_channels, (i + 1)*self.out_channels):\n",
    "                x_l.append(self.convolution_feed_x_l(y_l_minus_1[i], self.conv_w[j]))\n",
    "        x_l_final = []\n",
    "        for i in range(self.out_channels):\n",
    "            x_l_final.append(0)\n",
    "            for j in range(self.in_channels):\n",
    "                x_l_final[-1] += x_l[j*self.out_channels + i]\n",
    "            x_l_final[-1] += self.conv_b[len(x_l_final)-1]\n",
    "        self.y_l_minus_1 = y_l_minus_1  \n",
    "        return x_l_final\n",
    "\n",
    "    def backprop(self, dEdx_l, learning_rate):\n",
    "        list_of_dEdy_l_minus_1 = []\n",
    "        for i in range(self.out_channels):\n",
    "            dEdb_l = dEdx_l[i].sum()\n",
    "            self.conv_b[i] = self.conv_b[i] - learning_rate * dEdb_l\n",
    "        for i in range(self.in_channels):\n",
    "            dEdy_l_minus_1 = 0\n",
    "            k = 0\n",
    "            for j in range(i*self.out_channels, (i + 1)*self.out_channels):\n",
    "                dEdw_l = self.convolution_back_dEdw_l(\n",
    "                    y_l_minus_1=self.y_l_minus_1[i],\n",
    "                    dEdx_l=dEdx_l[k],\n",
    "                )\n",
    "                dEdy_l_minus_1 += self.convolution_back_dEdy_l_minus_1(\n",
    "                    dEdx_l=dEdx_l[k],\n",
    "                    w_l=self.conv_w[j],\n",
    "                    y_l_minus_1_shape=self.y_l_minus_1[i].shape,\n",
    "                )\n",
    "                self.conv_w[j] = self.conv_w[j] - learning_rate * dEdw_l\n",
    "                k += 1\n",
    "            list_of_dEdy_l_minus_1.append(dEdy_l_minus_1)\n",
    "        return list_of_dEdy_l_minus_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d3d7ae79",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid:\n",
    "    def __call__(self, x_l):\n",
    "        x_l = np.array(x_l, dtype=np.float32)\n",
    "        y_l = 1 / (1+np.exp(-x_l))\n",
    "        self.y_l = y_l  \n",
    "        return y_l\n",
    "\n",
    "    def backprop(self, dEdy_l):\n",
    "        dy_ldx_l = self.y_l * (1 - self.y_l)\n",
    "        dEdx_l = dEdy_l * dy_ldx_l\n",
    "        return dEdx_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d49a026f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax:\n",
    "    def __call__(self, x_l):\n",
    "        x_l = np.array(x_l, dtype=np.float32)\n",
    "        y_l = np.exp(x_l) / np.exp(x_l).sum()\n",
    "        self.y_l = y_l  \n",
    "        return y_l\n",
    "\n",
    "    def backprop(self, dEdy_l):\n",
    "        dy_ldx_l = np.zeros((self.y_l.shape[1], self.y_l.shape[1]), dtype=np.float32)\n",
    "        for i in range(dy_ldx_l.shape[1]):\n",
    "            for j in range(dy_ldx_l.shape[1]):\n",
    "                if i == j:\n",
    "                    dy_ldx_l[i][i] = self.y_l[0][i]*(1 - self.y_l[0][i])\n",
    "                else:\n",
    "                    dy_ldx_l[i][j] = - self.y_l[0][i]*self.y_l[0][j]\n",
    "        dEdx_l = np.dot(dEdy_l, dy_ldx_l)\n",
    "        return dEdx_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "08c73123",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU:\n",
    "    def __call__(self, x_l):\n",
    "        x_l = np.array(x_l, dtype=np.float32)\n",
    "        y_l = np.where(x_l > 0, x_l, 0)\n",
    "        self.y_l = y_l  \n",
    "        return y_l\n",
    "\n",
    "    def backprop(self, dEdy_l):\n",
    "        dy_ldx_l = np.where(self.y_l <= 0, self.y_l, 1)\n",
    "        dEdx_l = dEdy_l * dy_ldx_l\n",
    "        return dEdx_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "80d71aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Maxpool2d:\n",
    "    def __init__(\n",
    "        self, kernel_size, stride=1, kernel_center=(0, 0), padding=0,\n",
    "        convolution=False\n",
    "    ):\n",
    "        if isinstance(kernel_size, tuple):\n",
    "            self.kernel_size = kernel_size\n",
    "        else:\n",
    "            self.kernel_size = (kernel_size, kernel_size)\n",
    "        self.kernel_center = kernel_center\n",
    "        self.stride = stride\n",
    "        self.convolution = convolution\n",
    "        if convolution and padding > 0:\n",
    "            raise AssertionError(\"Padding in maxpooling can not be in \"\n",
    "                                 \"convolution, due to the inverted kernel\")\n",
    "        assert padding <= int(min(self.kernel_size) / 2), \\\n",
    "            \"Pad should be smaller than or equal to half of kernel size.\"\n",
    "        self.padding = padding\n",
    "\n",
    "    def maxpool(self, y_l):\n",
    "        y_l = np.pad(y_l, self.padding, constant_values=-np.inf)\n",
    "        indexes_a, indexes_b = get_axes_indexes(self.kernel_size, self.kernel_center)\n",
    "        stride = self.stride\n",
    "        h_out = int((y_l.shape[0] - (self.kernel_size[0]-1) - 1) / stride + 1)\n",
    "        w_out = int((y_l.shape[1] - (self.kernel_size[1]-1) - 1) / stride + 1)\n",
    "        y_l_mp = np.zeros((h_out, w_out), dtype=np.float32)\n",
    "        y_l_mp_to_y_l = np.zeros((h_out, w_out), dtype='<U32')\n",
    "        if self.convolution:\n",
    "            g = 1  \n",
    "        else:\n",
    "            g = -1 \n",
    "        for i in range(h_out):\n",
    "            for j in range(w_out):\n",
    "                result = -np.inf\n",
    "                element_exists = False\n",
    "                for a in indexes_a:\n",
    "                    for b in indexes_b:\n",
    "                        if (\n",
    "                            i*stride - g*a >= 0\n",
    "                            and j*stride - g*b >= 0\n",
    "                            and i*stride - g*a < y_l.shape[0]\n",
    "                            and j*stride - g*b < y_l.shape[1]\n",
    "                        ):\n",
    "                            if y_l[i*stride - g*a][j*stride - g*b] > result:\n",
    "                                result = y_l[i*stride - g*a][j*stride - g*b]\n",
    "                                i_back = i*stride - g*a - self.padding\n",
    "                                j_back = j*stride - g*b - self.padding\n",
    "                                element_exists = True\n",
    "                if element_exists:\n",
    "                    y_l_mp[i][j] = result\n",
    "                    y_l_mp_to_y_l[i][j] = str(i_back) + ',' + str(j_back)\n",
    "        return y_l_mp, y_l_mp_to_y_l\n",
    "\n",
    "    def __call__(self, y_l):\n",
    "        list_of_y_l_mp = []\n",
    "        self.list_of_y_l_mp_to_y_l = []\n",
    "        for i in range(len(y_l)):\n",
    "            y_l_mp, y_l_mp_to_y_l = self.maxpool(y_l[i])\n",
    "            list_of_y_l_mp.append(y_l_mp)\n",
    "            self.list_of_y_l_mp_to_y_l.append(y_l_mp_to_y_l)\n",
    "        self.y_l_shape = y_l[0].shape\n",
    "        return list_of_y_l_mp\n",
    "\n",
    "    def backprop(self, dEdy_l_mp):\n",
    "        list_of_dEdy_l = []\n",
    "        for i in range(len(dEdy_l_mp)):\n",
    "            dEdy_l = np.zeros(self.y_l_shape, dtype=np.float32)\n",
    "            for k in range(dEdy_l_mp[i].shape[0]):\n",
    "                for e in range(dEdy_l_mp[i].shape[1]):\n",
    "                    coordinates = self.list_of_y_l_mp_to_y_l[i][k][e]\n",
    "                    coordinate_row = int(coordinates[:coordinates.find(',')])\n",
    "                    coordinate_col = int(coordinates[coordinates.find(',')+1:])\n",
    "                    dEdy_l[coordinate_row][coordinate_col] += dEdy_l_mp[i][k][e]\n",
    "            list_of_dEdy_l.append(dEdy_l)\n",
    "        return list_of_dEdy_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "360fd2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear:\n",
    "    def __init__(self, in_features, out_features):\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.init_weights()\n",
    "\n",
    "    def load_weights(self, weight_name, bias_name, load_path):\n",
    "        self.fc_w = load_weight_from_npy(weight_name, load_path)\n",
    "        self.fc_b = load_weight_from_npy(bias_name, load_path)\n",
    "\n",
    "    def init_weights(self):\n",
    "        self.fc_w = self.init_weight((self.in_features, self.out_features))\n",
    "        self.fc_b = self.init_weight((1, self.out_features))\n",
    "\n",
    "    def init_weight(self, weight_shape):\n",
    "        weight = 2 * np.random.random(weight_shape) - 1\n",
    "        return weight\n",
    "\n",
    "    def __call__(self, y_l_minus_1):\n",
    "        x_l = np.dot(y_l_minus_1, self.fc_w) + self.fc_b\n",
    "        self.y_l_minus_1 = y_l_minus_1  # need for backprop\n",
    "        return x_l\n",
    "\n",
    "    def backprop(self, dEdx_l, learning_rate):\n",
    "        dEdw_l = np.dot(self.y_l_minus_1.T, dEdx_l)\n",
    "        dEdb_l = dEdx_l\n",
    "        dEdy_l_minus_1 = np.dot(dEdx_l, self.fc_w.T)\n",
    "        self.fc_w = self.fc_w - learning_rate * dEdw_l\n",
    "        self.fc_b = self.fc_b - learning_rate * dEdb_l\n",
    "        return dEdy_l_minus_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7c757a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrossEntropyLoss:\n",
    "    def __call__(self, target, predict):\n",
    "        return -target * np.log(predict)\n",
    "\n",
    "    def backprop(self, target, predict):\n",
    "        return -(target/predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c04a524c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSELoss:\n",
    "    def __call__(self, target, predict):\n",
    "        return (target - predict)**2\n",
    "\n",
    "    def backprop(self, target, predict):\n",
    "        return predict - target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "a97d4a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten:\n",
    "    def matrices2vector(self, matrices):\n",
    "        vector = np.array([[]], dtype=np.float32)\n",
    "        self.matrix_shape = matrices[0].shape\n",
    "        for i in range(len(matrices)):\n",
    "            reshaped_matrix = np.reshape(\n",
    "                matrices[i], (1, self.matrix_shape[0]*self.matrix_shape[1]))\n",
    "            vector = np.hstack((vector, reshaped_matrix))\n",
    "        return vector\n",
    "\n",
    "    def vector2matrices(self, vector):\n",
    "        matrices = []\n",
    "        matrix_size = self.matrix_shape[0]*self.matrix_shape[1]\n",
    "        for i in range(0, vector.size, matrix_size):\n",
    "            matrix = np.reshape(vector[0][i:i+matrix_size], self.matrix_shape)\n",
    "            matrices.append(matrix)\n",
    "        return matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "8aad5955",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Cnn:\n",
    "    def __init__(self):\n",
    "        self.conv1 = Conv2d(1, 2, 3, 1)\n",
    "        self.conv2 = Conv2d(2, 5, 2, 2, padding=1)\n",
    "        self.max_pool = Maxpool2d(2, 2, padding=1)\n",
    "        self.fc1 = Linear(320, 100)\n",
    "        self.fc2 = Linear(100, 10)\n",
    "        self.flatten = Flatten()\n",
    "        self.relu = ReLU()\n",
    "        self.sigmoid1 = Sigmoid()\n",
    "        self.sigmoid2 = Sigmoid()\n",
    "        self.softmax = Softmax()\n",
    "\n",
    "    def load_weights(self, load_path):\n",
    "        self.conv1.load_weights('conv_w_1', 'conv_b_1', load_path)\n",
    "        self.conv2.load_weights('conv_w_2', 'conv_b_2', load_path)\n",
    "        self.fc1.load_weights('fc_w_1', 'fc_b_1', load_path)\n",
    "        self.fc2.load_weights('fc_w_2', 'fc_b_2', load_path)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.max_pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.sigmoid1(x)\n",
    "        x = self.flatten.matrices2vector(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.sigmoid2(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "    def backprop(self, x, lr=0.01):\n",
    "        x = self.softmax.backprop(x)\n",
    "        x = self.fc2.backprop(x, lr)\n",
    "        x = self.sigmoid2.backprop(x)\n",
    "        x = self.fc1.backprop(x, lr)\n",
    "        x = self.flatten.vector2matrices(x)\n",
    "        x = self.sigmoid1.backprop(x)\n",
    "        x = self.conv2.backprop(x, lr)\n",
    "        x = self.max_pool.backprop(x)\n",
    "        x = self.relu.backprop(x)\n",
    "        x = self.conv1.backprop(x, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "485f2685",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_dataset(num_classes=3, max_images_per_class=100):\n",
    "    transforms = torchvision.transforms.Compose([\n",
    "        PIL2numpy(),\n",
    "        Normalize(),\n",
    "    ])\n",
    "    target_transform = torchvision.transforms.Compose([\n",
    "        OneHot()\n",
    "    ])\n",
    "\n",
    "    train_dataset = torchvision.datasets.FashionMNIST(\n",
    "        root='./data',\n",
    "        train=True,\n",
    "        download=True,\n",
    "        transform=transforms,\n",
    "        target_transform=target_transform\n",
    "    )\n",
    "\n",
    "    train_dataset.data = train_dataset.data[train_dataset.targets < num_classes]\n",
    "    train_dataset.targets = [t for t in train_dataset.targets if t < num_classes]\n",
    "\n",
    "    if max_images_per_class is not None:\n",
    "        class_counts = [0] * num_classes\n",
    "        filtered_indices = []\n",
    "        for i, label in enumerate(train_dataset.targets):\n",
    "            if class_counts[label] < max_images_per_class:\n",
    "                class_counts[label] += 1\n",
    "                filtered_indices.append(i)\n",
    "        train_dataset = Subset(train_dataset, filtered_indices)\n",
    "\n",
    "    test_dataset = torchvision.datasets.FashionMNIST(\n",
    "        root='./data',\n",
    "        train=False,\n",
    "        download=True,\n",
    "        transform=transforms,\n",
    "        target_transform=target_transform\n",
    "    )\n",
    "\n",
    "    test_dataset.data = test_dataset.data[test_dataset.targets < num_classes]\n",
    "    test_dataset.targets = [t for t in test_dataset.targets if t < num_classes]\n",
    "\n",
    "    return train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "a22dcb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataset, model, criterion, print_log_freq, lr):\n",
    "    loss_log = []\n",
    "    acc_log = []\n",
    "    losses = []\n",
    "    accuracies = []\n",
    "    start_time = time.time()\n",
    "    for idx, (image, target) in enumerate(dataset):\n",
    "        pred = model([image])\n",
    "        loss = criterion(target, pred)\n",
    "        x = criterion.backprop(target, pred)\n",
    "        model.backprop(x, lr=lr)\n",
    "\n",
    "        loss_log.append(loss.sum())  \n",
    "        acc_log.append((pred.argmax() == target.argmax()).item())  \n",
    "        if idx % print_log_freq == 0:\n",
    "            loss_avg = sum(loss_log[-print_log_freq:]) / print_log_freq\n",
    "            acc_avg = sum(acc_log[-print_log_freq:]) / print_log_freq\n",
    "            losses.append(loss_avg)\n",
    "            accuracies.append(acc_avg)\n",
    "            loop_time = time.time() - start_time\n",
    "            start_time = time.time()\n",
    "            print(f'Train step {idx}, Loss: {loss_avg:.5f}, '\n",
    "                  f'Acc: {acc_avg:.4f}, time: {loop_time:.1f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "279f8ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_samples(dataset):\n",
    "    class_labels = dataset.dataset.classes\n",
    "    num_classes = len(class_labels)\n",
    "    fig, axes = plt.subplots(1, num_classes, figsize=(15, 3))\n",
    "\n",
    "    for i, class_label in enumerate(class_labels):\n",
    "        class_indices = [index for index, label in enumerate(dataset.dataset.targets) if label == i]\n",
    "        if class_indices: \n",
    "            class_index = class_indices[0]\n",
    "            img, label = dataset.dataset[class_index]\n",
    "            img_tensor = TF.to_tensor(img)  \n",
    "            axes[i].imshow(img_tensor.permute(1, 2, 0)) \n",
    "            axes[i].set_title(class_label)\n",
    "            axes[i].axis('off')\n",
    "        else:\n",
    "            axes[i].axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "68412e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_log_freq = 25\n",
    "num_epochs = 1\n",
    "lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "33d9c261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset, test_dataset = get_train_dataset(num_classes=2, max_images_per_class=100)\n",
    "show_samples(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "0ba8df7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train step 0, Loss: 0.00019, Acc: 0.0400, time: 0.4\n",
      "Train step 25, Loss: 0.02705, Acc: 1.0000, time: 11.2\n",
      "Train step 50, Loss: 0.02875, Acc: 1.0000, time: 11.4\n",
      "Train step 75, Loss: 0.05460, Acc: 0.9600, time: 11.4\n",
      "Train step 100, Loss: 0.01264, Acc: 1.0000, time: 11.7\n",
      "Train step 125, Loss: 0.01281, Acc: 1.0000, time: 11.5\n",
      "Train step 150, Loss: 0.01436, Acc: 1.0000, time: 11.2\n",
      "Train step 175, Loss: 0.00505, Acc: 1.0000, time: 12.5\n"
     ]
    }
   ],
   "source": [
    "criterion = CrossEntropyLoss()/\n",
    "for epoch in range(num_epochs):\n",
    "    train_loop(train_dataset, model, criterion, print_log_freq, lr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
